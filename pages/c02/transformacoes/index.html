<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Transformações de variáveis aleatórias</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  
    <link rel="stylesheet" href="/notas_sde/libs/highlight/github.min.css">
    <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
    <script src="/notas_sde/libs/highlight/julia.min.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre').forEach((el) => {
          hljs.highlightElement(el);
        });
      });
    </script>
  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.3. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/literated/c01/simulacoes_numericas">1.4. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_Browniano">1.5. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movBrowniano">1.6. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/relacoes_rode_sde">1.7. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/identidades">2.5. Identidades fundamentais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades importantes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/borel_cantelli">2.10. Lema de Borel-Cantelli</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.11. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/gerando_num_aleatorios">2.12. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/definicao_pe">3.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_discretos">3.2. Processos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_continuos">3.3. Processos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/tipos_processos">3.4. Tipos de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/cadeias_markov">3.5. Processos de Markov</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_processo_wiener">4.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/existencia_processo_wiener">4.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/simetrias_wiener">4.3. Simetrias do processo de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/naodiferenciabilidade_wiener">4.4. Não-diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/variacao_ilimitada_wiener">4.5. Variação ilimitada quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/simulacoes_wiener">4.6. Simulações de processs de Wiener</a></li>
    </div>
    <div class="menu-level-1">
    <li>5. Integração estocástica</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_processos_estocasticos">5.1. Integrais de Riemann de processos estocásticos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/integral_continua_estocastica">5.2. Integrais de funções diferenciáveis com respeito a processos estocásticos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c05/riemann_wiener">5.3. Limites de somatórios de Riemann envolvendo o processo de Wiener</a></li>
    </div>
    <div class="menu-level-1">
    <li>6. Equações diferenciais aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c06/pathwise_solutions">6.1. Soluções por caminhos</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_extension_kolmogorov">Teorema de Extensão de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/convergencias"><kbd>→</kbd> 2.9. Tipos de convergências</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">2.8. Transformações de variáveis aleatórias</a></h1>
<p>A partir de uma ou mais variáveis aleatórias, podemos obter novas variáveis aleatórias aplicando transformações no espaço de eventos.</p>
<h2 id="transformação_de_uma_variável_aleatória"><a href="#transformação_de_uma_variável_aleatória" class="header-anchor">Transformação de uma variável aleatória</a></h2>
<p>Por exemplo, se \(X\) é uma variável aleatória com espaço de eventos \((\Sigma_1, \mathcal{E_1})\) e \(f:(\Sigma_1, \mathcal{E_1}) \rightarrow (\Sigma_2, \mathcal{E_2})\) é uma função mensurável desse espaço em outro, então</p>
\[
Y = f(X)
\]
<p>denota uma variável aleatória com eventos em \(\Sigma_2\). Dado um evento \(E \in \mathcal{E}_2\), a probabilidade de \(Y\) assumir valores em \(E\) é dada por</p>
\[
\mathbb{P}_Y(Y \in E) = \mathbb{P}_X(f(X) \in E) = \mathbb{P}_X(X \in f^{-1}(E)),
\]
<p>onde</p>
\[
f^{-1}(E) = \{x \in \Sigma_1; \;f(x)\in E\}.
\]
<p>Um dos exemplos mais triviais possíveis é</p>
\[
Y = aX + b
\]
<p>No caso de \(X\) ser uma distribuição uniforme, então \(Y\) também será uniforme:</p>
\[
X \sim \mathrm{Unif}(x_1, x_2) \quad \Longrightarrow \quad Y \sim \mathrm{Unif}(b + ax_1, b + ax_2).
\]
<p>No caso de \(X\) ser normal, então \(Y\) também será normal:</p>
\[
X \sim \mathcal{N}(\mu, \sigma^2) \quad \Longrightarrow \quad Y \sim \mathcal{N}(b + a\mu, a^2\sigma^2).
\]
<p>Observe, por exemplo, que</p>
\[
\mathbb{E}[Y] = \mathbb{E}[aX + b] = a\mathbb{E}[X] + b = a\mu + b
\]
<p>e</p>
\[
\mathbb{E}[(Y - \mathbb{E}[Y])^2] = \mathbb{E}[(aX + b - a\mu - b)^2] = a^2\mathbb{E}[(X-\mu)^2] = a^2\sigma^2.
\]
<p>Mas isso não mostra que \(Y\) é uma normal. Para ver isso, seja \(F\) a função de probabilidade acumulada de \(X\), i.e.</p>
\[
F_X(x) = \mathbb{P}(X \leq x) = \frac{1}{\sqrt{2\pi \sigma^2}}\int_{-\infty}^x e^{- \frac{(\xi - \mu)^2}{2\sigma^2}}\;\mathrm{d}\xi.
\]
<p>Então a função de probabilidade acumulada de \(Y\) é</p>
\[
F_Y(y) = \mathbb{P}(Y \leq y) = \mathbb{P}(aX + b \leq y) = \mathbb{P}\left(X \leq \frac{y - b}{a}\right) = F_X\left(\frac{y - b}{a}\right) = \frac{1}{\sqrt{2\pi \sigma^2}}\int_{-\infty}^{\frac{y - b}{a}} e^{- \frac{(\xi - \mu)^2}{2\sigma^2}}\;\mathrm{d}\xi.
\]
<p>Fazendo \(\eta = b + a\xi\), de modo que \((\eta - b)/a = \xi\) e \(\mathrm{d}\xi = \mathrm{d}\eta / a\), temos</p>
\[
F_Y(y) = \frac{1}{\sqrt{2\pi a^2\sigma^2}}\int_{-\infty}^y e^{- \frac{(\eta - b - a\mu)^2}{2a^2\sigma^2}}\;\mathrm{d}\eta.
\]
<p>Isso prova que \(Y \sim \mathbb{N}(b + a\mu, a^2\sigma^2)\).</p>
<h2 id="transformação_de_várias_variáveis_aleatórias"><a href="#transformação_de_várias_variáveis_aleatórias" class="header-anchor">Transformação de várias variáveis aleatórias</a></h2>
<p>Também podemos fazer isso para várias variáveis aleatórias, digamos \(X_1, \ldots, X_n\), em espaços de probabilidades \((\Omega_j, \mathcal{A}_j, \mathbb{P}_{X_1})\), com valores em \((\Sigma_j, \mathcal{E}_j)\), através de uma função mensurável</p>
\[
f: \Sigma_1 \times \cdots \times \Sigma_2 \rightarrow \Sigma,
\]
<p>em um espaço de eventos \((\Sigma, \mathcal{E})\). O caso mais comum é quando todos os espaços de amostras são idênticos e quando todos os espaços de eventos também são idênticos, mas isso não é necessário.</p>
<p>Com isso, podemos definir uma variável aleatória</p>
\[
Y = f(X_1, \ldots, X_n).
\]
<p>Nesse caso, dado um evento \(E\in \mathcal{E}\), temos</p>
\[
\mathbb{P}_Y(Y \in E) = \mathbb{P}((X_1, \dots, X_n) \in f^{-1}(E)),
\]
<p>onde \(\mathbb{P}\) se refere à probabilidade conjunta \(\mathbb{P} = \mathbb{P}_1 \times \cdots \times \mathbb{P}_n\), na \(\sigma\)-algebra \(\mathcal{A} = \mathcal{A}_1 \times \cdots \mathcal{A}_n\) gerada no espaço produto \(\Omega = \Omega_1 \times \cdots \times \Omega_n\).</p>
<p>De fato, este pode ser visto como um caso particular do primeiro, considerando-se a variável aleatória vetorial \(X = (X_1, \ldots, X_n)\) em \((\Omega, \mathcal{A}, \mathbb{P})\), com \(f:\Sigma_1 \times \cdots \times \Sigma_n \rightarrow \Sigma\).</p>
<h2 id="combinação_linear_de_distribuições_normais_independentes"><a href="#combinação_linear_de_distribuições_normais_independentes" class="header-anchor">Combinação linear de distribuições normais independentes</a></h2>
<p>Como exemplo, sejam \(X_1\) e \(X_2\) duas distribuições normais independentes, digamos \(X_1, X_2 \sim \mathcal{N}(0, 1)\). Definimos</p>
\[
X = a_1 X_1 + a_2 X_2,
\]
<p>onde \(a_1, a_2 \in \mathbb{R}\). Dados \(\omega = (\omega_1, \omega_2)\) no espaço amostral \(\Omega_1 \times \Omega_2\), temos uma realização</p>
\[
X(\omega) = a_1 X_1(\omega_1) + a_2 X(\omega_2).
\]
<p>Podemos mostrar que \(X\) também é uma normal, com</p>
\[
X \sim \mathcal{N}(0, a_1^2 + a_2^2).
\]
<p>Mais geralmente, </p>
\[
X_1 \sim \mathcal{N}(\mu_1, \sigma_1^2), \; X_2 \sim \mathcal{N}(\mu_2, \sigma_2^2) \quad \Longrightarrow \quad a_1 X_1 + a_2 X_2 \sim \mathcal{N}(a_1\mu_1 + a_2\mu_2, a_1^2\sigma_1^2 + a_2^2\sigma_2^2).
\]
<p>Naturalmente, isso pode ser generalizado para uma combinação linear de um número arbitrário de normais.</p>
<p>Há várias demonstrações desse fato, através de cálculo explícito da função acumulada de probabilidade ou da função característica, por exemplo. Mas a mais simples e elegante usa argumentos de simetria da normal, mais precisamente de argumentos de simetria por rotação da função densidade de probabilidades conjuntas de normais independentes com mesma variância. Mesmo que elas não tenham a mesma variância, podemos reescaloná-las. Vamos seguir, aqui, a demonstração como feita em Eisenberg &amp; Sullivan &#40;2008&#41;. Veja esse mesmo artigo para comentários sobre outras demonstrações.</p>
<p>Se \(X_1 \sim \mathcal{N}(\mu_1, \sigma_1^2)\) e \(X_2 \sim \mathcal{N}(\mu_2, \sigma_2^2)\), então podemos escrever \(X_1 = \mu_1 + \sigma_1 Y_1\) e \(X_2 = \mu_2 + \sigma_2 Y_2\), com \(Y_1, Y_2 \sim \mathcal{N}(0, 1)\). Assim,</p>
\[
X = a_1\mu_1 + a_2\mu_2 + a_1\sigma_1 Y_1 + a_2\sigma_2 Y_2.
\]
<p>Nesse caso, \(X\) é apenas uma translação de uma combinação de normais com média zero e variância um:</p>
\[
X - a_1\mu_1 + a_2\mu_2 = a_1\sigma_1 Y_1 + a_2\sigma_2 Y_2
\]
<p>Então basta mostrar que</p>
\[
b_1 Y_1 + b_2 Y_2 \sim \mathcal{N}(0, b_1^2 + b_2^2),
\]
<p>com \(b_1 = a_1\sigma_1\) e \(b_2 = a_2\sigma_2\). Para provar isso, trabalhamos com a função acumulada de probabilidade &#40;conjunta&#41;</p>
\[
F(x) = \mathbb{P}(b_1 Y_1 + b_2 Y_2 \leq x).
\]
<p>Como a função densidade de probabilidades da distribuição conjunta é simétrica em relação a rotações em torno da origem e como a reta \(b_1 Y_1 + b_2 Y_2 = x\) está a uma distância</p>
\[
d = \frac{x}{\sqrt{b_1^2 + b_2^2}}
\]
<p>da origem, então podemos fazer uma rotação do semiplano \(b_1 Y_1 + b_2 Y_2 \leq x\) para o semiplano \(Y_1 \leq d\).</p>

<img src="/notas_sde/assets/pages/c02/transformacoes/code/output/combinacao_linear_normais_rotacao.svg" alt="">
<p>Fazendo isso, teremos a mesma probabilidade:</p>
\[
F(x) = \mathbb{P}(b_1 Y_1 + b_2 Y_2 \leq x) = \mathbb{P}(Y_1 \leq d) = F_{Y_1}\left(\frac{x}{\sqrt{b_1^2 + b_2^2}}\right) = F_{(b_1^2 + b_2^2)Y_1}(x).
\]
<p>Ou seja, \(F\) é igual à função de densidade de probabilidades da normal \(\mathcal{N}(0, b_1^2 + b_2^2)\), concidindo, portanto, com essa normal.</p>

<p><img src="/notas_sde/assets/pages/c02/transformacoes/code/output/combinacao_linear_normais1.svg" alt=""> <img src="/notas_sde/assets/pages/c02/transformacoes/code/output/combinacao_linear_normais2.svg" alt=""></p>
<p>Um caso particular que será explorado na demonstração de existência de um processo de Wiener é a independência da soma e da diferença de normais independentes e identicamente distribuídas com média zero.</p>
<p>Sejam \(X, Y \sim \mathcal{N}(0, \sigma^2)\) independentes. Defina</p>
\[
Z = X + Y, \qquad W = X - Y.
\]
<p>Primeiramente, como combinações lineares de normais, temos, pelo que acabamos de ver, que \(Z\) e \(W\) também são normais. Como \(X\) e \(Y\) têm média zero e variância \(\sigma^2\), então \(Z\) e \(W\) também têm média zero e variância \(a^2\sigma_1^2 + b^2\sigma_2^2 = 2\sigma^2\), onde \(\sigma_1 = \sigma_2 = \sigma\), \(a = 1\) e \(b = \pm 1\). Assim,</p>
\[
Z, W \sim \mathcal{N}(0, 2\sigma^2).
\]
<p>Agora, para ver a independência entre \(Z\) e \(W\), ...</p>
<h2 id="exercícios"><a href="#exercícios" class="header-anchor">Exercícios</a></h2>
<ol>
<li><p>Seja \(Y\) uma variável aleatória real e defina \(X = \sin(Y)\). Suponha que \(\mathbb{E}[Y] = 0\). Mostre que \(\mathbb{E}[X] = 0\) e \(\mathrm{Var}(X) \leq \mathrm{Var}(Y)\).</p>
</li>
</ol>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/convergencias"><kbd>→</kbd> 2.9. Tipos de convergências</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: June 01, 2022. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    
        <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>
    

  </body>
</html>
