<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Variáveis aleatórias contínuas</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  
    <link rel="stylesheet" href="/notas_sde/libs/highlight/github.min.css">
    <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
    <script src="/notas_sde/libs/highlight/julia.min.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre').forEach((el) => {
          hljs.highlightElement(el);
        });
      });
    </script>
  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações diferenciais aleatórias e estocásticas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.3. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/literated/c01/simulacoes_numericas">1.4. Simulações numéricas de modelos de crescimento natural</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_Browniano">1.5. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/passeioaleatorio_movBrowniano">1.6. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/relacoes_rode_sde">1.7. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/identidades">2.5. Identidades fundamentais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.6. Desigualdades importantes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/multi_va">2.7. Variáveis aleatórias multivariadas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/transformacoes">2.8. Transformações de variáveis aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/convergencias">2.9. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.10. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/gerando_num_aleatorios">2.11. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/definicao_pe">3.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_discretos">3.2. Processos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_continuos">3.3. Processos contínuos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/tipos_processos">3.4. Tipos de processos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/cadeias_markov">3.5. Processos de Markov</a></li>
    </div>
    <div class="menu-level-1">
    <li>4. Processos de Wiener</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/definicao_processo_wiener">4.1. Definição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/existencia_processo_wiener">4.2. Existência de processos de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/simetrias_wiener">4.3. Simetrias do processo de Wiener</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/naodiferenciabilidade_wiener">4.4. Não-diferenciabilidade quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/variacao_ilimitada_wiener">4.5. Variação ilimitada quase sempre dos caminhos amostrais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c04/simulacoes_wiener">4.6. Simulações de processs de Wiener</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/media_momentos"><kbd>→</kbd> 2.4. Média, variância e outros momentos</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">2.3. Variáveis aleatórias contínuas</a></h1>
<p>Uma variável aleatória contínua assume valores em \(\mathbb{R}\). A probabilidade de um determinado valor \(x\) ocorrer é expressa por</p>
\[
\mathbb{P}(X = x).
\]
<p>Também podemos expressar a probabilidade de um certo conjunto \(E\) de valores ocorrer:</p>
\[
\mathbb{P}(X \in E).
\]
<p>Em Teoria da Medida, escreveríamos isso simplesmente como \(\mathbb{P}(E)\). De qualquer forma, não é necessário escrever o conjunto de forma explícita. Por exemplo, se quisermos saber a probabilidade da variável aleatória ser positiva, podemos escrever</p>
\[
\mathbb{P}(X > 0)
\]
<p>ao invés de \(\mathbb{P}(X \in (0, \infty))\). Aqui, estamos representando \(E = \{ X > 0 \} = \{x \in \mathbb{R}; \;x > 0\} = (0, \infty)\).</p>
<p>A <strong>função acumulada de probabilidades</strong> é dada, como no caso discreto, por</p>
\[
f(x) = \mathbb{P}(X \leq x), \quad x \in \mathbb{R}.
\]
<p>A função acumulada de probabilidade define unicamente a variável aleatória &#40;a menos de um conjunto de medida nula&#41;.</p>
<p>Em muitos casos, podemos expressar uma probabilidade contínua em termos de uma <strong>função de densidade de probabilidades</strong> \(p(x)\), de tal forma que</p>
\[
\mathbb{P}(X \in E) = \int_\mathbb{R} \chi_E(x) p(x) \;\mathrm{d}x = \int_E p(x) \;\mathrm{d}x,
\]
<p>onde \(\chi_E(x)\) é a função característica de um conjunto \(E\), ou seja, vale \(1\), se \(x\in E\), caso contrário, vale \(0\).</p>
<p>Se \(E = \{a \leq X \leq b}\), temos, em particular,</p>
\[
  \mathbb{P}(a \leq X \leq b) = \int_a^b p(x) \;\mathrm{d}x.
\]
<p>Necessariamente, a função densidade de probabilidades deve ser não-negativa e ter massa 1:</p>
\[
p(x) \geq 0, \qquad \int p(x) \;\mathrm{d}x = 1.
\]
<p>Observe que a função distribuição de probabilidades é a derivada da função acumulada de probabilidades. De fato, temos, formalmente,</p>
\[
  f(x) = \mathbb{P}(X \leq x) = \int_{-\infty}^x p(x) \;\mathrm{d}x,
\]
<p>de maneira que</p>
\[
  p(x) = \frac{\mathrm{d}f(x)}{\mathrm{d}x}.
\]
<p>Portanto, a função densidade de probabilidades só existe quando a função acumulada de probabilidades é derivável quase sempre. Esse resultado pode ser generalizado para contexto bem mais gerais de acordo com o <strong>Teorema de Radon-Nikodym</strong>.</p>
<p>Vejamos alguns exemplos de variáveis aleatórias contínuas.</p>
<h2 id="distribuição_uniforme"><a href="#distribuição_uniforme" class="header-anchor">Distribuição uniforme</a></h2>
<p>Dado um intervalo finito \(I\subset \mathbb{R}\), a distribuição uniforme está associada a uma variável que pode assumir qualquer valor nesse intervalo, com a mesma probabilidade. A função de densidade de probabilidades é um múltiplo da função característica do intervalo \(I\):</p>
\[
f(x) = \frac{1}{|I|}\chi_I(x) = \begin{cases} \displaystyle \frac{1}{|I|}, & x \in I, \\ 0, & x \notin I, \end{cases}
\]
<p>onde \(|I|\) é o comprimento de \(I\), já que devemos ter massa um, \(\int f = 1\). Observe que, como o intervalo \(I\) é contínuo, as chances de termos um valor específico \(x_0\) é nula. Mas as chances de termos um valor em um determinado subintervalo \(J\subset I\) são iguais à fração do comprimento desse intervalo no intervalo total, i.e.</p>
\[
\mathbb{P}(X \in J) = \frac{|J|}{|I|}
\]
<p>Uma distribuição uniforme em um intervalo \(I\) é denotada por \(\mathcal{U}_I\) e escrevemos</p>
\[
X \sim \mathcal{U}_I.
\]
<p>Por exemplo, caso \(I = [\alpha, \beta)\), então a variável aleatória \(X \sim \mathcal{U}_{[\alpha, \beta)}\) tem sua função densidade de probabilidades dada por</p>
\[
f(x) = \begin{cases} \displaystyle \frac{1}{\beta - \alpha}, & \alpha \leq x < \beta, \\ 0, & x < \alpha \text{ ou } x \geq \beta. \end{cases}
\]

<img src="/notas_sde/assets/pages/c02/exemplos_va_continuas/code/output/cdfuniform.svg" alt="">
<h2 id="distribuição_normal"><a href="#distribuição_normal" class="header-anchor">Distribuição normal</a></h2>
<p>A distribuição normal com média \(\mu\) e desvio padrão \(\sigma\), ou seja, variância \(\sigma^2\), é denotada por \(\mathcal{N}(\mu, \sigma^2)\). Sua função densidade de probabilidades é</p>
\[
  f(x) = \frac{1}{2\pi \sigma^2} e^{\displaystyle - \frac{x^2}{2\sigma^2}}.
\]
<p>Uma variável aleatória cuja distribuição é dada por uma normal é designada por</p>
\[
  X \sim \mathcal{N}(\mu, \sigma^2)
\]
<p>Vimos, por exemplo, nos modelos para o movimento Browniano, que a variável aleatória \(X_t\) para a posição da partícula no instante \(t\) é uma normal com média \(0\) e variância \(2Dt\), para algum \(D > 0\), ou seja</p>
\[
  X_t \sim \mathcal{N}(0, 2Dt), \quad t > 0.
\]

<img src="/notas_sde/assets/pages/c02/exemplos_va_continuas/code/output/cdfnormal.svg" alt="">
<h2 id="delta_de_dirac"><a href="#delta_de_dirac" class="header-anchor">Delta de Dirac</a></h2>
<p>Um exemplo fundamental e que não possui função densidade de probabilidades é a distribuição <strong>delta de Dirac</strong>. Em termos de variáveis aleatórias, ela aparece quando o valor é dado com probabilidade 1, e.g. \(X = x_0\) com probabilidade 1. Nesse caso, temos</p>
\[
\mathbb{P}(X = x_0) = 1, \qquad \mathbb{P}(X \neq x_0) = 0.
\]
<p>A distribuição de probabilidades associada a essa variável é exatamente a delta de Dirac no ponto \(x_0\), denotada por \(\delta_{x_0}\). Ou seja,</p>
\[
X \sim \delta_{x_0}.
\]
<p>Vimos esse exemplo no caso do movimento Browniano, onde a posição inicial da partícula é a origem. Em termos de variáveis aleatórias, escrevemos \(X_0 = 0\),  <em>quase certamente</em>, i.e.</p>
\[
X_0 \sim \delta_0.
\]
<p>A delta de Dirac também pode ser obtida como limite da distribuição normal, quando a variância converge para zero:</p>
\[
\mathcal{N}(\mu, \sigma^2) \rightarrow \delta_\mu, \quad \text{quando } \sigma \rightarrow 0,
\]
<p>para qualquer \(\mu\) fixo &#40;ou mesmo com \(\mu\) variando e convergindo para um determinado valor \(\mu_0\), caso em que teríamos \(\delta_{\mu_0}\), no limite&#41;.</p>
<p>O limite acontece <em>no sentido fraco</em> &#40;veremos melhor isso posteriormente&#41;, i.e. para qualquer função contínua limitada \(f:\mathbb{R} \rightarrow \mathbb{R}\), temos</p>
\[
\mathbb{E}_{\mathcal{N}(\mu, \sigma^2)}(f) \rightarrow \mathbb{E}_{\delta_\mu}(f) = f(\mu);
\]
<p>Essa convergência fraca não implica na convergência \(\mathbb{P}_{\mathcal{N}(\mu, \sigma^2)}(E) \rightarrow \mathbb{P}_{\delta_0}(E)\), para qualquer conjunto mensurável \(E\). De fato, seja \(\mu = 0\), para simplificar, e considere \(A = [0, \infty)\) e \(B = (0, \infty)\). Então, \(\mathbb{P}_{\delta_0}(A) = 1\) e \(\mathbb{P}_{\delta_0}(B) = 0\), enquanto que \(\mathbb{P}_{\mathcal{N}(0, \sigma^2)}(A) = \mathbb{P}_{\mathcal{N}(0, \sigma^2)}(B) = 1/2\), para todo \(\sigma > 0\). Tal convergência só acontece quando \(E\) é um conjunto de continuidade em relação a \(\delta_0\), i.e. \(\delta_0(\partial E) = 0\), o que não é o caso de \(A\) e \(B\).</p>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c02/media_momentos"><kbd>→</kbd> 2.4. Média, variância e outros momentos</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: May 19, 2022. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    
        <script src="/notas_sde/libs/highlight/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>
    

  </body>
</html>
