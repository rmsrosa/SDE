<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="" />
  <meta name="author" content="and contributors" />
   <title>Cadeias de Markov</title>  
  <link rel="shortcut icon" type="image/png" href="/notas_sde/assets/images/favicon_randgon.png"/>
  <link rel="stylesheet" href="/notas_sde/css/base.css"/>
  
    <link rel="stylesheet" href="/notas_sde/css/base_showaside.css"/>
  
  <script src="/notas_sde/libs/mousetrap/mousetrap.min.js"></script>

  

  
    <link rel="stylesheet" href="/notas_sde/libs/katex/katex.min.css">
  
</head>

<body>

  <div class="books-container">

  <aside class="books-menu">
  <input type="checkbox" id="menu">
  <label for="menu">☰</label>

  <div class="books-title">
    <a href="/notas_sde/">Equações Diferenciais Estocásticas e Aleatórias</a>
  </div>

  <br />

  <div class="books-subtitle">
    Aspectos Teóricos e Numéricos
  </div>

  <br />

  <div class="books-author">
    <a href="https://rmsrosa.github.io">Ricardo M. S. Rosa</a>
  </div>

  <div class="books-menu-content">
    <div class="menu-level-1">
    <li>1. Introdução</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/apresentacao">1.1. Apresentação</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_iniciais">1.2. Equações estocásticas e aleatórias</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/aspectos_numericos">1.3. Aspectos numéricos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/literated/c01/simulacoes_numericas">1.4. Simulações numéricas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/movimento_Browniano">1.5. Movimento Browniano</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c01/relacoes_rode_sde">1.6. Relações entre equações estocásticas e equações aleatórias</a></li>
    </div>
    <div class="menu-level-1">
    <li>2. Variáveis Aleatórias</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/definicao_va">2.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_discretas">2.2. Variáveis aleatórias discretas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/exemplos_va_continuas">2.3. Variáveis aleatórias contínuas</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/media_momentos">2.4. Média, variância e outros momentos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/desigualdades">2.5. Desigualdades importantes</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/teorema_central">2.6. Teorema Central do Limite</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c02/gerando_num_aleatorios">2.7. Gerando números aleatórios no computador</a></li>
    </div>
    <div class="menu-level-1">
    <li>3. Processos Estocásticos</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/definicao_pe">3.1. Conceitos essenciais</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/processos_discretos">3.2. Processos discretos</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/cadeias_markov">3.3. Cadeias de Markov</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/funcoes_distribuicao">3.4. Funções de distribuição</a></li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/c03/passeioaleatorio_movBrowniano">3.5. Do passeio aleatório ao movimento Browniano</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/convergencias">4. Tipos de convergências</a></li>
    </div>
    <div class="menu-level-1">
    <li>Apêndice</li>
    </div>
    <div class="menu-level-2">
    <li><a href="/notas_sde/pages/appendix/teo_fund_kolmogorov">Teorema Fundamental de Kolmogorov</a></li>
    </div>
    <div class="menu-level-1">
    <li><a href="/notas_sde/pages/references">References</a></li>
    </div>
<div>


  
    <a href="https://github.com/rmsrosa/notas_sde"><img src="/notas_sde/assets/images/GitHub-Mark-32px.png" alt="GitHub repo" width="18" style="margin:5px 5px" align="left"></a>

  

</aside>


  <div class="books-content">

    
      <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c03/processos_discretos">3.2. Processos discretos <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c03/funcoes_distribuicao"><kbd>→</kbd> 3.4. Funções de distribuição</a>
</span>
    </p>
</div>
</br></br>

    

    
      
    
<h1 id="get_title"><a href="#get_title" class="header-anchor">3.3. Cadeias de Markov</a></h1>
<p><strong>Cadeias de Markov</strong>, também chamadas de <strong>processos de Markov</strong>, são processos estocásticos em que a mudança de estado para um estado futuro, conhecendo-se o estado atual, não depende dos estados passados. Mais precisamente, se \(\{X_t\}_{t\in I}\) é um processo aleatório e \(t_1 < t_2 < \ldots < t_n < t_{n+1}\) pertencem a \(I\), então, dados \(X_{t_1} = x_1, X_{t_2} = x_2, \ldots, X_{t_n} = x_n\), temos que \(X_{t_{n+1}}\) só depende de \(X_{t_n}\), ou seja</p>
\[
\mathbb{P}(X_{t_{n+1}} = x | X_{t_1} = x_1, X_{t_2} = x_2, \ldots, X_{t_n} = x_n) = \mathbb{P}(X_{t_{n+1}} = x | X_{t_n} = x_n).
\]
<p>Processos de Markov são chamados de <em>sem memória</em> e podem ser contínuos ou discretos, com o espaço de estados também podendo ser contínuo ou discreto.</p>
<p>O processo de Bernoulli é um exemplo trivial de uma cadeia de Markov discreta. O passeio aleatório é outro exemplo. O modelo de Einstein para o movimento Browniano, por sua vez, é um exemplo de um processo de Markov contínuo. Já o modelo da urna sem recomposição, como tratado anteriormente, não é uma cadeia de Markov, já que cada passo depende do estado do sistema em todos os passos anteriores.</p>
<h2 id="revisitando_o_problema_da_urna"><a href="#revisitando_o_problema_da_urna" class="header-anchor">Revisitando o problema da urna</a></h2>
<p>Conforme formulado inicialmente, o problema da urna não é uma cadeia de Markov. Mas podemos modelar o problema de outra forma, para que seja uma cadeia de Markov. Lembramos que começamos com \(N\) bolinhas de cada cor. Podemos denotar por \(X_n\) o <em>total</em> de bolinhas vermelhas retiradas da urna <em>até</em> o passo \(n\), inclusive. Para o passo \(n + 1\), só há duas possibilidades: \(X_{n + 1} = X_n + 1\), caso uma bolinha vermelha seja retirada, ou \(X_{n + 1} = X_n\), caso a bolinha retirada seja da cor preta. Todos os outros estados tem probabilidade nula de ocorrer.</p>
<p>Observe que, inicialmente, temos um total de \(2N\) bolinhas. Após \(n\) retiradas, sobram \(2N - n\) bolinhas. Por sua vez, inicialmente temos \(N\) bolinhas de cada cor. Após retirarmos \(X_n\) bolinhas vermelhas, temos \(N - X_n\) vermelhas restantes. As outras \((2N - n) - (N - X_n) = N - n + X_n\) são bolinhas pretas. Assim, podemos expressar as probabilidades de cada uma das duas realizações possíveis na forma</p>
\[
\mathbb{P}(X_{n + 1} = X_n + 1) = \frac{N - X_n}{2N - n},
\]
<p>e</p>
\[
\mathbb{P}(X_{n + 1} = X_n + 1) = \frac{N - n + X_n}{2N - n}.
\]
<h2 id="probabilidades_de_transição"><a href="#probabilidades_de_transição" class="header-anchor">Probabilidades de transição </a></h2>
<p>Quando temos um número discreto de estados possíveis, podemos determinar a evolução do processo em termos das probabilidades do estado ir de um valor \(j\), no instante \(n\), para um valor \(i\), no instante \(n+1\). Isso nos leva a definir as <strong>probabilidades de transição</strong></p>
\[
  p_{ij}^n = \mathbb{P}(X_{n+1} = i | X_n = j).
\]
<p>O processo é <strong>temporalmente homogêneo</strong> quando as probabilidades de transição são independentes do parâmetro, i.e. \(p_{ij}^n = p_{ij}\) independe de \(n\).</p>
<p>Quando o conjunto de possíveis estados é finito, isso nos dá uma <strong>matriz de transição</strong>,</p>
\[
P_n = (p_{ij}^n).
\]
<p>Observe que cada <em>coluna</em> da matriz de transição deve ter soma igual a</p>
\[
\sum_i p_{ij} = 1, \qquad \forall j.
\]
<p>No caso de um processo de Bernoulli com estados \(\{1, 0\}\) &#40;e.g. sucesso e fracasso&#41; ocorrendo com probabilidades \(p\) e \(1 - p\), respectivamente, temos a matriz de transição</p>
\[
P_n = P = \left[ \begin{matrix} p & p \\ 1 - p & 1 - p \end{matrix} \right].
\]
<p>No caso do passeio aleatório, temos um espaço de estados enumerável, \(\Omega = \mathbb{Z}\), e as probabilidades de transição são</p>
\[
p_{ij} = \mathbb{P}(X_{n+1} = i | X_n = j) = \begin{cases} 1/2, & j = i \pm 1, \\ 0, & \text{caso contrário} \end{cases}.
\]
<h2 id="previsão_ingênua_de_tempo"><a href="#previsão_ingênua_de_tempo" class="header-anchor">Previsão ingênua de tempo</a></h2>
<p>Vamos imaginar, agora, um problema de previsão de tempo, em que classificamos o tempo em três estados: &quot;ensolarado&quot;, &quot;nublado&quot; e &quot;chuvoso&quot;. Seja \(X_n\) o estado do sistema no \(n\)-ésimo dia, com \(1\), \(2\) e \(3\) indicando cada um desses possíveis estados, respectivamente.</p>
<p>Vamos assumir que, a partir de uma &quot;análise criteriosa do histórico do clima em uma determinada região e uma determinada época&quot;, observamos que, em média, após um dia ensolarado, temos 70&#37; de chances de termos outro dia ensolarado, 20&#37; de termos um dia nublado e 10&#37; de termos um dia chuvoso. Após um dia nublado, as chances são de 30&#37;, 40&#37;, 30&#37;, respectivamente. E após um dia chuvoso, as chances são de 20&#37;, 40&#37; e 40&#37;.</p>
<p>Como temos um número finito de estados e as probabilidades de transição são estacionárias, podemos definir a matriz de transição de estados \(P = (p_{ij})_{ij}\) por</p>
\[
p_{ij} = \mathbb{P}(X_{n+1} = i | X_n = j)
\]
<p>No nosso caso, temos</p>
\[
P = \left[ \begin{matrix} 0.7 & 0.3 & 0.2 \\ 0.2 & 0.4 & 0.4 \\ 0.1 & 0.3 & 0.4 \end{matrix} \right]
\]
<p>Previsões de longo prazo podem ser feitas iterando-se a matriz de transição:</p>
\[
X_{n+k} \sim P^kX_n, \quad k = 1, 2, \ldots.
\]
<p>Por exemplo, se em determinado momento \(n\) temos \(X_n = 1\), ou seja, temos um dia ensolarado, então daqui a dois dias teremos</p>
\[
X_{n+2} \sim P^2 X_1 = \left[ \begin{matrix} 0.57 & 0.39 & 0.17 \\ 0.26 & 0.44 & 0.36 \\ 0.17 & 0.27 & 0.3 \end{matrix} \right] \left(\begin{matrix} 1 \\ 0 \\ 0 \end{matrix}\right) = \left(\begin{matrix} 0.57 \\ 0.26 \\ 0.17 \end{matrix}\right),
\]
<p>ou seja, \(57\%\) de termos um dia ensolarado, \(13\%\) de termos um dia nublado e \(17\%\) de termos um dia chuvoso.</p>
<h2 id="distribuições_estacionárias_de_processos_temporalmente_homogêneos"><a href="#distribuições_estacionárias_de_processos_temporalmente_homogêneos" class="header-anchor">Distribuições estacionárias de processos temporalmente homogêneos</a></h2>
<p>No caso de um processo temporalmente homogêneo em um espaço de eventos finitos \(\{1, \ldots, J\}\), a matriz de transição \(P\) é independente do parâmetro temporal. Além disso, como as colunas somam \(1\), a matriz tem necessariamente um autovalor igual a \(1\). De fato, a matriz transposta \(P^t\) tem as suas linhas somando \(1\), de modo que</p>
\[
P^t \left(\begin{matrix} 1 \\ \vdots \\ 1 \end{matrix}\right) = \left(\begin{matrix} \sum_{i=1}^J p_{i1} \\ \vdots \\ \sum_{i=1}^J p_{iJ} \end{matrix}\right) = \left(\begin{matrix} 1 \\ \vdots \\ 1 \end{matrix}\right),
\]
<p>ou seja, \(P^t\) tem um autovalor igual a \(1\). Em particular, \(\det(P^t - I) = 0\), portanto \(\det(P - I) = \det(P^t - I) = 0\) e \(P\) também possui um autovalor igual a \(1\).</p>
<p>Isso implica na existência de &#40;pelo menos&#41; um autovalor \(v=(v_1, \ldots, v_J) \in \mathbb{R}^J\) tal que</p>
\[
Pv = v
\]
<p>Isso nos dá uma distribuição estacionária</p>
\[
\mathbb{P}(X_n = i) = v_i.
\]
<p>Por exemplo, no caso da previsão ingênua de tempo, </p>
\[
P = \left[ \begin{matrix} 0.7 & 0.3 & 0.2 \\ 0.2 & 0.4 & 0.4 \\ 0.1 & 0.3 & 0.4 \end{matrix} \right]
\]
<p>Os autovalores são aproximadamente \(0.0438\), \(0.4562\) e \(1\). O autoespaço associado ao autovalor \(1\) é</p>
\[
V_1 = \{(6s, 4s, 3s); \;s\in \mathbb{R}\}.
\]
<p>O autovalor com elementos não negativos e com norma \(1\) é</p>
\[
v = \frac{1}{13}(6, 4, 3) \approx (0.4615, 0.3077, 0.1338).
\]
<p>Assim, a distribuição com probabilidades de aproximadamente \(46,15\%\) de sol, \(30,77\%\) de nuvens e \(13,38\%\) de chuva é uma distribuição estacionária. &#40;Ela está associada a média de dias ensolarados, nublados e chuvosos coletados para a análise&#41;. Ou seja, se em um determinado dia essas são as probabilidades para a previsão para o dia seguinte, então as previsões a longo prazo serão iguais a essa. Podemos interpretar \(v\) como sendo essa lei de distribuição de probabilidades.</p>
<p>Como, nesse caso, há um único autovalor igual a \(1\) e os outros dois são estritamente menores do que \(1\), então a previsão &quot;assintótica&quot; é igual a essa obtida pela análise de autovalores: \(\lim_{k\rightarrow \infty} P^{n + k}X_n \sim v\) &#40;escrevemos assim pois \(v\) não é o valor da variável aleatória, mas, sim, a lei de distribuição de probabilidades associada a essa variável aleatória limite&#41;.</p>
<p>Além de, necessariamente, ter um autovalor igual a \(1\), qualquer matriz de transição tem autovalores com valor absoluto entre \(0\) e \(1\), mas eles podem ser negativos ou complexos.</p>
<h2 id="exercícios"><a href="#exercícios" class="header-anchor">Exercícios</a></h2>
<ol>
<li><p>Qualquer matriz cujos elementos sejam não negativos e cujas colunas tenham soma igual a \(1\) define um processo de Markov. Tais matrizes são chamadas de <strong>matrizes de Markov</strong>. Encontre os autovalores das seguintes matrizes de Markov, observando que podemos ter &#40;a&#41; autovalores nulos; &#40;b&#41; autovalores negativos; &#40;c&#41; mais de um autovalor igual a \(1\); e &#40;d&#41; autovalores complexos conjugados:</p>
</li>
</ol>
\[
\textrm{(a) } P = \left[ \begin{matrix} 1 & 1 \\ 0 & 0 \end{matrix} \right], \qquad
\textrm{(b) } P = \left[ \begin{matrix} 0 & 1 \\ 1 & 0 \end{matrix} \right]
\]
\[
\textrm{(c) } P = \left[ \begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix} \right], \qquad
\textrm{(d) } P = \left[ \begin{matrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0\end{matrix} \right]
\]
<ol start="2">
<li><p>Mostre que quando \(1\) é o único autovalor com valor absoluto igual a \(1\), de uma matriz de Markov \(P\), então \(P^ku\) converge para um autovetor associado a esse autovalor. Se o autoespaço desse autovalor tiver dimensão um, então esse limite independe do vetor inicial \(u\), desde que ela esteja associada a uma distribuição de probabilidades, ou seja, que seja um vetor com norma \(1\).</p>
</li>
<li><p>Encontre os autoespaços associados aos autovalores das matrizes &#40;c&#41; e &#40;d&#41; do exercício acima, obtenha as distribuições de probabilidade associadas a esses autovalores e observe que existem distribuições cíclicas, ou seja, que se repetem após dois ou mais passos.</p>
</li>
</ol>

    <div class="navbar">
    <p id="nav">
<span id="nav-prev" style="float: left;">
<a class="menu-level-1" href="/notas_sde/pages/c03/processos_discretos">3.2. Processos discretos <kbd>←</kbd></a>
</span>
<span id="nav-next" style="float: right;">
    <a class="menu-level-1" href="/notas_sde/pages/c03/funcoes_distribuicao"><kbd>→</kbd> 3.4. Funções de distribuição</a>
</span>
    </p>
</div>
</br></br>



<div class="page-foot">
    
        <div class="license">
            <a href=https://creativecommons.org/licenses/by-nc-nd/4.0/>(CC BY-NC-ND 4.0) Attribution-NonCommercial-NoDerivatives 4.0 International </a>
            Ricardo M. S. Rosa
        </div>
    

    Last modified: April 25, 2022. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>, using the <a href="https://github.com/rmsrosa/booksjl-franklin-template">Book Template</a>.
</div><!-- CONTENT ENDS HERE -->

      </div> <!-- .books-content -->
    </div> <!-- .books-container -->

    
        <script src="/notas_sde/libs/katex/katex.min.js"></script>
        <script src="/notas_sde/libs/katex/auto-render.min.js"></script>
        <script>renderMathInElement(document.body)</script>
    

    

  </body>
</html>
